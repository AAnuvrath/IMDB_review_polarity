{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744e939d",
   "metadata": {},
   "source": [
    "<p style=\"font-size:36px;text-align:center\"> <b>IMDB review classifier</b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01d260",
   "metadata": {},
   "source": [
    "<h1>2. Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a87064",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from random import randint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from scipy.sparse import hstack\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20c3278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 499381.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# unpacking the data from txt file to list\n",
    "reviews = []\n",
    "rating = []\n",
    "f = open(\"imdb_labelled.txt\", \"r\")\n",
    "all_data = f.read().split(\"\\n\")\n",
    "for data in tqdm(all_data):\n",
    "    row = data.split(\"\\t\")\n",
    "    reviews.append(row[0].strip())\n",
    "    rating.append(int(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6066585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size is:  1000\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Rating\n",
       "0  A very, very, very slow-moving, aimless movie ...       0\n",
       "1  Not sure who was more lost - the flat characte...       0\n",
       "2  Attempting artiness with black & white and cle...       0\n",
       "3         Very little music or anything to speak of.       0\n",
       "4  The best scene in the movie was when Gerardo i...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe containg reviews and rating\n",
    "all_train = pd.DataFrame(list(zip(reviews, rating)), columns =['Reviews', 'Rating'])\n",
    "print(\"Train data set size is: \", all_train.shape[0])\n",
    "print(100*'-')\n",
    "all_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1569f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking duplicate rows\n",
    "#train[train.duplicated(keep = False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8580b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data remaining after removing dulicate rows:  99.7 %\n"
     ]
    }
   ],
   "source": [
    "train=all_train.drop_duplicates(subset={\"Reviews\"}, keep='first', inplace=False) #dropping duplicate data points\n",
    "#Checking to see how much % of data still remains\n",
    "print(\"Data remaining after removing dulicate rows: \",(train['Rating'].size)/(all_train['Rating'].size)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6230c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of data points')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.countplot(y = train.Rating)\n",
    "plt.title('Distribution of data points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c009c2a",
   "metadata": {},
   "source": [
    "<h1>3. Pre-Processing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a982fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4720fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion dealing with punctuations\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    \n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5bd376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 997/997 [00:00<00:00, 31132.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining above \n",
    "preprocessed_reviews = []\n",
    "for sentance in tqdm(train['Reviews'].values):\n",
    "    sentance = decontracted(sentance)        #puncuation\n",
    "    sentance = re.sub('[^A-Za-z1-10]+', ' ', sentance) #special characteristics\n",
    "    sentance = ' '.join(w.lower() for w in sentance.split() if w.lower() not in stopwords)  #stop words and lower case\n",
    "    preprocessed_reviews.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "932c69fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size is:  997\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = pd.DataFrame(list(zip(preprocessed_reviews, rating)), columns =['Preprocessed_Reviews', 'Rating'])\n",
    "print(\"Train data set size is: \", preprocessed_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e42c28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow moving aimless movie distressed drifting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure lost flat characters audience nearly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempting artiness black white clever camera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little music anything speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best scene movie gerardo trying find song keep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Preprocessed_Reviews\n",
       "0  slow moving aimless movie distressed drifting ...\n",
       "1  not sure lost flat characters audience nearly ...\n",
       "2  attempting artiness black white clever camera ...\n",
       "3                        little music anything speak\n",
       "4  best scene movie gerardo trying find song keep..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = preprocessed_train['Rating'].values\n",
    "X = preprocessed_train.drop(['Rating'], axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48b7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e8467",
   "metadata": {},
   "source": [
    "<h2>3.1. Feature enginering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c74c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(847, 4) (847,)\n",
      "(150, 4) (150,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "sentiScoresTrainList=[]\n",
    "sentiScoresTestList=[]\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in X_train['Preprocessed_Reviews'].values:\n",
    "    sentiScores = sid.polarity_scores(sentence)\n",
    "    sentiScoresTrainList.append(list(sentiScores.values()))\n",
    "\n",
    "for sentence in X_test['Preprocessed_Reviews'].values:\n",
    "    sentiScores = sid.polarity_scores(sentence)\n",
    "    sentiScoresTestList.append(list(sentiScores.values()))\n",
    "    \n",
    "X_train_sentiscores = np.array(sentiScoresTrainList)\n",
    "X_test_sentiscores = np.array(sentiScoresTestList)\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_sentiscores.shape, y_train.shape)\n",
    "print(X_test_sentiscores.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a032debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 1) (847,)\n",
      "(150, 1) (150,)\n",
      "====================================================================================================\n",
      "After vectorizations\n",
      "(847, 576) (847,)\n",
      "(150, 576) (150,)\n",
      "====================================================================================================\n",
      "NOTE: THE NUMBER OF COLUMNS IN EACH OF THE VECTOR WONT BE SAME\n"
     ]
    }
   ],
   "source": [
    "# Apply TF-IDF vectorization on 'Preprocessed_Essay' \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(min_df=3,ngram_range=(1,3))\n",
    "vectorizer_tfidf.fit(X_train['Preprocessed_Reviews'].values) # fit has to happen only on train data\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_tfidf = vectorizer_tfidf.transform(X_train['Preprocessed_Reviews'].values)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test['Preprocessed_Reviews'].values)\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(X_train_tfidf.shape, y_train.shape)\n",
    "print(X_test_tfidf.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"NOTE: THE NUMBER OF COLUMNS IN EACH OF THE VECTOR WONT BE SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28a846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(847, 580) (847,)\n",
      "(150, 580) (150,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Joining all the features\n",
    "X_tr_tfidf=hstack((X_train_sentiscores, X_train_tfidf)).tocsr()\n",
    "X_te_tfidf = hstack((X_test_sentiscores, X_test_tfidf)).tocsr()\n",
    "\n",
    "\n",
    "print(\"Final Data matrix\")\n",
    "print(X_tr_tfidf.shape, y_train.shape)\n",
    "print(X_te_tfidf.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e00ae",
   "metadata": {},
   "source": [
    "<h1>4. Machine Learning Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1825693",
   "metadata": {},
   "source": [
    "<h2>4.1. Random model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "967f28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 150189.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 847/847 [00:00<00:00, 424137.47it/s]\n"
     ]
    }
   ],
   "source": [
    "y_test_rand=[]\n",
    "for i in tqdm(range(0,150)):\n",
    "    y_test_rand.append(randint(0, 1))\n",
    "    \n",
    "y_train_rand=[]\n",
    "for i in tqdm(range(0,847)):\n",
    "    y_train_rand.append(randint(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d21e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for a random model is:  0.4722550177095632\n",
      "Test accuracy for a random model is:  0.5\n",
      "Train f1 score for a random model is:  0.4697508896797153\n",
      "Test f1 score for a random model is:  0.5161290322580646\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy for a random model is: \",accuracy_score(y_train, y_train_rand))\n",
    "print(\"Test accuracy for a random model is: \",accuracy_score(y_test, y_test_rand))\n",
    "print(\"Train f1 score for a random model is: \",f1_score(y_train, y_train_rand))\n",
    "print(\"Test f1 score for a random model is: \",f1_score(y_test, y_test_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7822fa1",
   "metadata": {},
   "source": [
    "<h2>4.2. Logistic regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40670676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Perform Hyperparameter Tuning.\n",
    "# Plot the training and the CV AUC scores, for different values of 'alpha', using a 2D line plot\n",
    "probs = LogisticRegression(random_state=42)\n",
    "\n",
    "parameters = {'C': [ 0.001, 0.05, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100,500,1000]}\n",
    "clf = RandomizedSearchCV(probs, parameters, cv=3, scoring='accuracy',return_train_score=True,random_state=42)\n",
    "clf.fit(X_tr_tfidf, y_train)\n",
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "275bb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logi = LogisticRegression(C=1, random_state=42)\n",
    "logi.fit(X_tr_tfidf, y_train)\n",
    "y_pred_train = logi.predict(X_tr_tfidf)\n",
    "y_pred_test = logi.predict(X_te_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b20d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for a Logistic regression is:  0.8134592680047226\n",
      "Test accuracy for a Logistic regression is:  0.6866666666666666\n",
      "Train f1 score for a Logistic regression is:  0.8204545454545453\n",
      "Test f1 score for a Logistic regression is:  0.6887417218543047\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy for a Logistic regression is: \",accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test accuracy for a Logistic regression is: \",accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train f1 score for a Logistic regression is: \",f1_score(y_train, y_pred_train))\n",
    "print(\"Test f1 score for a Logistic regression is: \",f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47a407",
   "metadata": {},
   "source": [
    "<h2>4.3. SVM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65246800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Perform Hyperparameter Tuning.\n",
    "# Plot the training and the CV AUC scores, for different values of 'alpha', using a 2D line plot\n",
    "\n",
    "probs = svm.SVC(random_state=42)\n",
    "\n",
    "parameters = {'C': [ 0.001, 0.05, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100,500,1000]}\n",
    "clf = RandomizedSearchCV(probs, parameters, cv=3, scoring='accuracy',return_train_score=True,random_state=42)\n",
    "clf.fit(X_tr_tfidf, y_train)\n",
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17c25675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = svm.SVC(C=0.4,random_state=42)\n",
    "sv.fit(X_tr_tfidf, y_train)\n",
    "y_pred_train = sv.predict(X_tr_tfidf)\n",
    "y_pred_test = sv.predict(X_te_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0657e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for a Logistic regression is:  0.7804014167650531\n",
      "Test accuracy for a Logistic regression is:  0.7333333333333333\n",
      "Train f1 score for a Logistic regression is:  0.7937915742793793\n",
      "Test f1 score for a Logistic regression is:  0.7435897435897435\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy for a Logistic regression is: \",accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test accuracy for a Logistic regression is: \",accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train f1 score for a Logistic regression is: \",f1_score(y_train, y_pred_train))\n",
    "print(\"Test f1 score for a Logistic regression is: \",f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec343037",
   "metadata": {},
   "source": [
    "<h2>4.4. Random Forrest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd4c6445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "probs = RandomForestClassifier(random_state=42)\n",
    "\n",
    "parameters = {'n_estimators': [ 1, 5, 10, 50, 100], 'max_depth':[1,3,5,7,10]}\n",
    "clf = RandomizedSearchCV(probs, parameters, cv=3, scoring='accuracy',return_train_score=True,random_state=42)\n",
    "clf.fit(X_tr_tfidf, y_train)\n",
    "\n",
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7557666b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdf = RandomForestClassifier(n_estimators = 50, max_depth= 10, random_state=42)\n",
    "rdf.fit(X_tr_tfidf, y_train)\n",
    "y_pred_train = rdf.predict(X_tr_tfidf)\n",
    "y_pred_test = rdf.predict(X_te_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93a9a3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for random forrest is:  0.781582054309327\n",
      "Test accuracy for a random forrest is:  0.72\n",
      "Train f1 score for a random forrest is:  0.7960308710033076\n",
      "Test f1 score for a random forrest is:  0.7236842105263158\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy for random forrest is: \",accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test accuracy for a random forrest is: \",accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train f1 score for a random forrest is: \",f1_score(y_train, y_pred_train))\n",
    "print(\"Test f1 score for a random forrest is: \",f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ca289da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------+---------------+----------+---------+\n",
      "|        Model        | Train Accuracy | Test Accuracy | Train F1 | Test F1 |\n",
      "+---------------------+----------------+---------------+----------+---------+\n",
      "|     Worst/Random    |      0.47      |      0.50     |   0.47   |   0.52  |\n",
      "| Logistic regression |      0.81      |      0.68     |   0.82   |   0.69  |\n",
      "|         SVM         |      0.78      |      0.73     |   0.79   |   0.74  |\n",
      "|    Random forrest   |      0.78      |      0.72     |   0.80   |   0.72  |\n",
      "+---------------------+----------------+---------------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Specifying the Column Names while initializing the Table\n",
    "myTable = PrettyTable([\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Train F1\", \"Test F1\"])\n",
    "  \n",
    "# Adding rows\n",
    "myTable.add_row([\"Worst/Random\", \"0.47\", \"0.50\", \"0.47\" , \"0.52\"])\n",
    "myTable.add_row([\"Logistic regression\", \"0.81\", \"0.68\", \"0.82\", \"0.69\"])\n",
    "myTable.add_row([\"SVM\", \"0.78\", \"0.73\", \"0.79\", \"0.74\"])\n",
    "myTable.add_row([\"Random forrest\", \"0.78\", \"0.72\", \"0.80\", \"0.72\"])\n",
    "  \n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec50074",
   "metadata": {},
   "source": [
    "#### Summary Points\n",
    "<ol>\n",
    "    <li>From the above table, it can be seen that Best test score and accuracy is from SVM</li>\n",
    "    <li>Train and test accuracy of our best model(SVM) are close indicating model is not overfit</li>\n",
    "    <li>Adding sentiment scores improved performance metrics</li>\n",
    "    <li>Model can be improved with much larger data points</li>\n",
    "</ol>    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
